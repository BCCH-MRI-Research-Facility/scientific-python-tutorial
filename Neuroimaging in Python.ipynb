{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import standard modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import NiPy modules\n",
    "\n",
    "If you've installed python via miniconda, most packages are available by running `conda install package` in the terminal. In general, if a package is available through conda that's the easiest way to install it. Sometimes packages aren't available through conda, in which case you can use the python package installer, `pip`. If you're running this tutorial on `syzygy.ca`, conda is not installed so all packages are installed through pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user nipy nibabel dipy nilearn nipype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipy\n",
    "import nibabel as nib\n",
    "import dipy\n",
    "import nilearn\n",
    "import nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up some sample data\n",
    "\n",
    "First, we'll load up the MNI T1 template as \"t1img\". `nib.load()` returns an image object. The exact structure of the image object will depend on what type of file you load. Mostly you're\n",
    "\n",
    "Read more about nibabel image objects here: http://nipy.org/nibabel/nibabel_images.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img = nib.load('./MNI152_T1_2mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the image object is fast because it doesn't load the image data automatically. This lets you quickly access header information if that's all you want. To load the image data as a numpy array just call `get_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1data = t1img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a slice is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "f,ax = plt.subplots()\n",
    "sl=40\n",
    "t1slice = np.rot90(t1data[:,:,sl])\n",
    "t1im = ax.matshow(t1slice,cmap='gray')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maskimg = nib.load('./JHU-ICBM-labels-2mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maskdata = maskimg.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "sl=40\n",
    "t1slice = np.rot90(t1data[:,:,sl])\n",
    "t1im = ax.matshow(t1slice,cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "maskdata = np.ma.masked_equal(maskdata,0)\n",
    "maskslice = np.rot90(maskdata[:,:,sl])\n",
    "maskim = ax.matshow(maskslice,cmap='cool')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Choose colormaps carefully! \n",
    "\n",
    "https://matplotlib.org/users/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t1data and maskdata are both just numpy 3D arrays, so we perform normal array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskdata.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskdata.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1data[maskdata==1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (optional): Parse an atlas xml file\n",
    "\n",
    "* Parse the xml file using xml.etree.ElementTree\n",
    "* Determine how to access the index and text of each element\n",
    "* Loop over all the elements and place the data into a dictionary, with the label text as key and the index as value\n",
    "* Plot an ROI by calling it by it's string, ie 'Body of corpus callosum'\n",
    "* Evaluate the mean T1 in that ROI, again calling it by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = xml.etree.ElementTree.parse('JHU-labels.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = e.find('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data.findall('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.attrib['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeldict = {}\n",
    "for label in labels:\n",
    "    labeldict[label.text] = int(label.attrib['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "sl=45\n",
    "t1slice = np.rot90(t1data[:,:,sl])\n",
    "t1im = ax.matshow(t1slice,cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "# Set mask equal to zero except for desired label\n",
    "maskdata2 = maskdata.copy()\n",
    "maskdata2[maskdata2 != labeldict['Body of corpus callosum']] = 0\n",
    "# Make mask a numpy mask so zeros aren't plotted\n",
    "maskdata2 = np.ma.masked_equal(maskdata2,0)\n",
    "# select a slice\n",
    "maskslice = np.rot90(maskdata2[:,:,sl])\n",
    "# Overlay the mask on the image\n",
    "maskim = ax.matshow(maskslice,cmap='cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving modified images as Nifti files\n",
    "Let's make a copy of t1data and zero out voxels where maskdata==48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1data2 = t1data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1data2[maskdata==48] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the modified image\n",
    "\n",
    "Create a new nifti image object with `nib.Nifti1Image()`. It needs a image array and an affine matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1img2 = nib.Nifti1Image(t1data2,t1img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1img2.to_filename('t1img2.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nibabel has tools for opening multiple formats including PAR/REC\n",
    "Loading a PAR/REC image with nibabel and then saving to nifti is, in my experience, more robust than dcm2nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nib.parrec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nib.load?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (optional): Make a  pandas dataframe with the mean values for each ROI\n",
    "* Calculate the mean of each roi in the JHU atlas. Put in in a list or a dict\n",
    "* Create a new `pd.DataFrame()` with the list/dict as the data, the mask labels as the index, and a relevant string as the column header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(maskdata.max()):\n",
    "    mean = t1data[maskdata==i].mean()\n",
    "    means.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not very \"pythonic\". Avoid loops when you can do it in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = [ t1data[maskdata==i].mean() for i in range(1,maskdata.max()+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=means,columns=['Subject 1'],index=range(1,maskdata.max()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this for multiple subjects and you've started building a database that you can run stats on, save to Excel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the affine\n",
    "The affine matrix describes the relationship between the image matrix and the \"real world\" coordinate system. Image orientation manipulation should be approached with caution, but it's often necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.header.get_zooms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_t1img = nib.as_closest_canonical(t1img)\n",
    "canonical_t1img.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_t1img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "canonical_t1data = canonical_t1img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2)\n",
    "sl=45\n",
    "t1im = ax[0].matshow(np.rot90(t1data[:,:,sl]),cmap='gray')\n",
    "t1im_canon = ax[1].matshow(np.rot90(canonical_t1data[:,:,sl]),cmap='gray')\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice the difference?\n",
    "\n",
    "Hard to spot, but the canonical oriented image is flipped left/right from the standard image. If you have a sagitally acquired image, the image will be reoriented in more dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise: Rotate the image and the affine matrix by 90 degrees. Save and open in FSL. Are the orientation labels correct?\n",
    "\n",
    "http://nipy.org/nibabel/coordinate_systems.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Tissue segmentation\n",
    "\n",
    "http://nipy.org/dipy/examples_built/tissue_classification.html#example-tissue-classification\n",
    "\n",
    "Let's run a tissue classification algorithm on our T1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.data import fetch_tissue_data, read_tissue_data\n",
    "from dipy.segment.tissue import TissueClassifierHMRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tissue classes\n",
    "nclass = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smoothing factor. Good values 0-0.5\n",
    "beta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Markov Random Field classifier. Similar algorithm to FAST and ANTS\n",
    "hmrf = TissueClassifierHMRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_segmentation, final_segmentation, PVE = hmrf.classify(t1data, nclass, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_segmentation.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_segmentation.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(1,3)\n",
    "axs[0].matshow(np.rot90(final_segmentation[:,:,40]))\n",
    "axs[1].matshow(np.rot90(final_segmentation[:,50,:]))\n",
    "axs[2].matshow(np.rot90(final_segmentation[40,:,:]))\n",
    "\n",
    "[ax.set_axis_off() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PVE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(1,3)\n",
    "axs[0].matshow(np.rot90(PVE[:,:,40,1]))\n",
    "axs[1].matshow(np.rot90(PVE[:,50,:,1]))\n",
    "axs[2].matshow(np.rot90(PVE[40,:,:,1]))\n",
    "\n",
    "[ax.set_axis_off() for ax in axs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype: Integrate imaging software into your Python code\n",
    "\n",
    "https://miykael.github.io/nipype_tutorial/\n",
    "\n",
    "Nipype is an amazing utility that allows you to link together different non-Python imaging tools within your Python analysis. It can be used simply to (for example) add FSL's eddy correction processing to you Python DTI processing; or it can be used to organize your entire processing workflow.\n",
    "\n",
    "Personally I don't use the full workflow functionality. Instead I use it to call FSL and SPM functions from my Python scripts. It's much easier to write everything in pure Python instead of switching back and forth between FSL command line tools and SPM in Matlab. Nipype has an amazing number of interfaces, including:\n",
    "* FSL\n",
    "* SPM\n",
    "* FreeSurfer\n",
    "* niftireg\n",
    "* ANTS\n",
    "* AFNI\n",
    "* Camino\n",
    "* MIPAV\n",
    "* DTK\n",
    "\n",
    "Full list here: http://nipype.readthedocs.io/en/latest/documentation.html\n",
    "\n",
    "For the Nipype interfaces to work, you just have to have the software you want to use install and certain environmental variables set so that Python knows where to look for the programs. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $FSLDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these software tools are on the syzygy server. This example will only work on a computer with FSL installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.fsl as fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = fsl.FLIRT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flt.inputs.in_file = 'MNI152_T1_2mm.nii.gz'\n",
    "flt.inputs.reference = 'MNI152_T1_1mm.nii.gz'\n",
    "flt.inputs.out_file = 'MNI_T1_2mm_to_1mm.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = flt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_reg_file = results.outputs.out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_reg_file` is a string describing a path to a file. We can now use this variable as the input to another nipype interface, or we can load the nifti file into Python with the tools we learned previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: DTI processing\n",
    "http://nipy.org/dipy/examples_built/reconst_dti.html#example-reconst-dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "from dipy.data import read_stanford_hardi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, gtab = read_stanford_hardi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gtab (**g**radient **tab**le) is the object that holds the gradient information. This example gives it to us automatically. If you created your dti nifti file with dcm2nii, it probably also gave you  .bvec and .bval files. In that case, you could create the gtab with\n",
    "```\n",
    "from dipy.io import read_bvals_bvecs\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "from dipy.core.gradients import gradient_table\n",
    "gtab = gradient_table(bvals, bvecs)\n",
    "```\n",
    "\n",
    "If you're reading data straight from a PAR/REC file, \n",
    "```\n",
    "dtipar = nib.parrec.load(dti_par)\n",
    "bvals, bvecs = dtipar.header.get_bvals_bvecs()\n",
    "gtab = gradient_table(bvals, bvecs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = img.get_data()\n",
    "print('data shape: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(2,2)\n",
    "for ax, vol in zip(axs.flatten(),range(0,160,40)):\n",
    "    ax.matshow(np.rot90(data[:,:,25,vol]))\n",
    "    ax.set_axis_off()\n",
    "f.subplots_adjust(hspace=.05, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "maskdata, mask = median_otsu(data, 3, 1, False, vol_idx=range(10, 50), dilate=2)\n",
    "print('maskdata.shape {}' .format(maskdata.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "ax1.matshow(np.rot90(data[:,:,40,0]))\n",
    "ax2.matshow(np.rot90(maskdata[:,:,40,0]))\n",
    "ax3.matshow(np.rot90(mask[:,:,40]))\n",
    "ax1.set_axis_off()\n",
    "ax2.set_axis_off()\n",
    "ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TensorModel object with our gradient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take at least a minute, be patient\n",
    "tenfit = tenmodel.fit(maskdata,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.reconst.dti import fractional_anisotropy, color_fa, lower_triangular\n",
    "\n",
    "FA = fractional_anisotropy(tenfit.evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.rot90(FA[:,:,40]))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We can save the FA as a nifti, or do some numerical analysis on it with numpy, or make publication images, or whatever. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Add an eddy correction step to the above pipeline using a Nipype interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: fMRI analysis with ICA\n",
    "\n",
    "http://nilearn.github.io/connectivity/resting_state_networks.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some sample data. This data sample is already pre-processed -- normally you need to motion correct, etc.\n",
    "\n",
    "from nilearn import datasets\n",
    "\n",
    "adhd_dataset = datasets.fetch_adhd(n_subjects=4)\n",
    "func_filenames = adhd_dataset.func  # list of 4D nifti files for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn.decomposition import CanICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CanICA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "canica = CanICA(n_components=20, smoothing_fwhm=6.,\n",
    "                memory=\"nilearn_cache\", memory_level=2,\n",
    "                threshold=3., verbose=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take about a minute\n",
    "canica.fit(func_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the independent components in brain space\n",
    "components_img = canica.masker_.inverse_transform(canica.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_prob_atlas\n",
    "\n",
    "# Plot all ICA components together\n",
    "plot_prob_atlas(components_img, title='All ICA components',anat_img='MNI152_T1_2mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"z\", title=\"IC %d\" % i,\n",
    "                  cut_coords=1, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
